---
layout: post
title: "通过 llms.txt 引导 AI 高效使用网站内容"
date: 2025-04-01 20:00.000000000 +08:00
categories: [一得之愚集 ]
tags: [AI,大模型,llms-txt,SEO]
typora-root-url: ..
---

> 作为示例，本站也开始提供 `llms.txt` 和 `llms-full.txt` 的支持，可以参看下面的链接获取相关文件。
>
> <a class="btn" href="https://onevcat.com/llms.txt">llms.txt</a>
> 
> <a class="btn" href="https://onevcat.com/llms-full.txt">llms-full.txt</a>


## 什么是 llms.txt

大型语言模型（LLMs）是截止至训练日期时的人类知识的总集。而如果想要精确地解决更加实时的问题（比如在进行代码生成、研究辅助等任务中），我们可以通过搜索最新知识，依赖网络信息，来极大提升模型的准确性。然而，标准的 HTML 内容通常包含导航元素、JavaScript、CSS 和其他对于 LLMs 而言非必要的信息。这些冗余信息会在对话中占据 LLMs 有限的上下文窗口，也会干扰和降低处理效率。此外，LLMs 直接抓取和解析完整的 HTML 页面效率也很低下。为了应对这些挑战，`llms.txt` 应运而生，它是一个[正在讨论的标准（参见 llms-txt.org）](https://llmstxt.org/)，旨在为 LLMs 提供一个简洁、专业的网站内容概述，以单一且易于访问的 Markdown 文件格式呈现。`llms.txt` 就像一个网站的“指南”，引导 AI 系统找到站点上的关键信息，并以易于阅读和分析的结构化格式提供这些信息。

### llms.txt 的目的与益处

在使用带有搜索的 LLMs，或者是通过其他的搜索服务 API 将搜索内容传递给不带搜索的 LLMs 时，被搜索的网站内容是面向人类进行渲染的，它包含大量无关的视觉要素（CSS 样式，动画等）和功能性的内容（JavaScript，操作交互等），且主题往往不太明确，这会给 LLMs 增加理解难度。我们需要一种更加面向 AI 的网站内容检索方式。

`llms.txt` 是**放置在网站根目录下的一个文件**，它的核心目标是向 LLMs 提供结构化的、机器可读的信息，从而帮助它们在推理阶段更有效地利用网站内容。与面向搜索引擎的 `robots.txt` 和 `sitemap.xml` 不同，`llms.txt` 专为推理引擎优化，它的目标是通过以 AI 能够高效处理的格式提供内容结构，解决了 AI 相关的挑战。这种（还在提出阶段的）标准标志着一种向 AI 优先的文档和内容策略的转变。随着 AI 在网络内容消费中扮演越来越重要的角色，针对 AI 的理解进行优化将变得与针对人类用户和搜索引擎进行优化同样关键。

网站所有者也能从实施 `llms.txt` 中获益匪浅：AI 聊天机器人更有可能在其回复中引用那些提供了 `llms.txt` 文件的网站，从而提高网站在 AI 平台上的可见性。优化后的 `llms.txt` 文件还有可能在 AI 驱动的搜索体验中带来更好的可见性、更高的排名和更强的可发现性。

更清晰地理解 `llms.txt` 在网络标准中的定位，可以参考下表：

| **名称**      | **目的**                           | **目标受众** | **格式** |
| ------------- | ---------------------------------- | ------------ | -------- |
| `robots.txt`  | 控制搜索引擎爬虫对网站的访问       | 搜索引擎     | 文本     |
| `sitemap.xml` | 列出网站上所有可索引的页面         | 搜索引擎     | XML      |
| `llms.txt`    | 为大型语言模型提供结构化的内容概述 | 大型语言模型 | Markdown |

## 解剖 llms.txt 标准：关键组件与结构

`llms.txt` 标准现在定义了两种不同的文件：`/llms.txt` 和 `/llms-full.txt`。

- `/llms.txt` 提供了一个精简的网站文档导航视图，旨在帮助 AI 系统快速理解网站的结构，它通过链接提供了一个简洁、结构化的关键内容概述。
- `/llms-full.txt` 是一个包含所有文档内容的综合性文件，它将所有文档整合到一个单独的 Markdown 文件中，这个文件需要“包罗万象”，因此尺寸一般比较大。

这两种版本的存在使得网站所有者可以根据不同的用例和内容结构，选择向 LLMs 提供的信息详细程度。对于拥有大量文档的网站，以导航为中心的 `/llms.txt` 可以提供快速的路线图，而 `/llms-full.txt` 则提供完整的原始内容以供深入处理。

### llms.txt 的内容

对于 `/llms.txt` 文件，其必须遵循特定的 Markdown 语法和结构。

1. 文件应以网站或项目名称的一级标题（`#`）开头，随后可以有一个简短的项目描述的块引用（`>`），通常一到三句话即可。
2. 接下来的内容应使用二级标题（`##`）组织，例如“文档”、“示例”等，用于列出文档链接，创建逻辑区块（例如，“主要文档”、“产品”）
3. 这个二级标题下应该是一个列表，它包含相应的链接和简短的描述，格式为 `- [文档名称](URL): 简短描述`。此处的 URL 应该是等同于为人类准备的网页地址所等同的该文档的 md 格式文件。
4. 此外，还可以包含其他的二级区块，例如“可选资源”、或“隐私政策”等其他部分。一般会使用 `## Optional` 部分用于表示当上下文长度受限时可以省略的次要链接。

一个典型且简单的 `llms.txt` 文件内容如下：

```md
# 我的博客

> 这是我的博客，用来记录一些个人感兴趣的内容。

## 博客文章

- [什么是 llms.txt](https://example.com/article-1.md): 介绍什么是 llms.txt 以及它的主要特性
- [从监督学习到加强学习](https://example.com/article-2.md): 回顾和比较训练 LLM 时的主流学习方法和变迁过程

## 其他页面

- [关于我](https://example.com/about/index.html.md): 介绍博客站点作者：简单的生平和其他著作。
- [许可证](http://example.com/license/index.html.md): 描述网站内容的许可证信息

## 可选

- [GitHub 源码](https://github.com/example): 网站源代码
```

这种结构化的 Markdown 格式确保了 LLMs 可以轻松地解析和理解 `/llms.txt` 文件的内容和层级结构。Markdown 清晰的语法和明确的层级关系（标题、列表、链接）为 AI 模型提供了一种一致且易于处理的格式，从而减少了歧义并提高了信息提取的效率。

### llms-full.txt 的内容

相比之下，`/llms-full.txt` 的格式则更为直接，它是一个**包含所有文档内容**的单一、全面的 Markdown 文件。它应包含网站的所有文档，并整合到一个单独的 Markdown 文件中。为了优化 AI 的处理效率，建议移除文件中的非必要标记和脚本。最简单的方法，就是将所有驱动站点的内容（比如很多 markdown 文件）进行合并，然后生成这个巨大的内容文件。

`/llms-full.txt` 为 LLMs 提供了对完整内容的直接访问，无需进行额外的导航。对于需要深入理解所有可用信息的任务，以单一、清晰的格式提供完整的文档对于 LLMs 来说非常有益。常见的例子，比如某个技术产品（可以是编程语言，库，或者是面向用户的软件等）将文档和说明合并到一个 `llms-full.txt` 中，以供 AI 进行参考。

### 创建和放置 llms.txt

按照上述内容创建好文件后，就可以将它们放置在网站的根目录下，并公开给互联网访问了。llms.txt 的标准约定了文件的位置就是网站根目录，这类似于 `robots.txt` 和 `sitemap.xml` 的存放方式，简化了 LLMs 的发现过程。

另外，我们还可以在服务器配置中添加 `X-Robots-Tag: llms-txt` HTTP Header。这个值可以向 LLM 发出信号，表明网站提供了 `llms.txt` 文件。这并不是一个严格要求，但这个 header 值可以明确表明网站已采用 `llms.txt` 标准。

我们可以使用一些工具来验证某个网站是否实现了 llms.txt 标准，比如[这个 extension](https://chromewebstore.google.com/detail/llmstxt-checker/klcihkijejcgnaiinaehcjbggamippej?pli=1)。

## 在 AI 中使用 llms.txt

和主动抓取网络的搜索引擎或者爬虫不同，目前 LLMs 还不会自动发现和索引 `llms.txt` 文件（毕竟 llms-txt 还没有成为被完全认可的标准）。因此，我们还需要手动将文件内容提供给 AI 系统。这可以通过以下方式完成：

1. 直接向可以访问互联网的 AI 提供 `llms.txt` 或 `llms-full.txt` 文件的链接；
2. 对不能访问互联网的 AI，将 `llms.txt` 文件的内容直接复制到提示词中；
3. 或者，如果 AI 工具支持文件上传功能，则可以使用该功能上传 `llms.txt` 文件。

目前该标准仍处于早期阶段，但随着标准的普及，我们可能会看到 AI 系统发展出自动发现和使用 `llms.txt` 文件的能力，这会类似于搜索引擎处理 `robots.txt` 和 `sitemap.xml` 的方式。

值得注意的是，一些工具和平台已经开始支持 `llms.txt` 的集成。例如，Cursor 等平台允许用户添加和索引第三方文档（包括 `/llms-full.txt`），并在聊天中使用它们作为上下文。也有一些类似于 [llms.txt hub](https://llmstxthub.com/) 的网站为 llms.txt 提供了更方便的检索方式。

这些平台的出现表明人们越来越认识到 `llms.txt` 的价值。随着更多 AI 工具和平台集成对 `llms.txt` 的支持，其采用率和实用性可能会显著提高。因此，尽早完成适配，可能会对你的网站内容在 AI 时代占有一席之地提供帮助。

### llms.txt 工具与实际案例

目前有多种工具可以帮助生成 `llms.txt` 文件，从而简化了创建过程，使得网站所有者更容易采用该标准。例如：

- dotenv 开发的 `llmstxt` 是一个开源的命令行工具，可以基于网站的 `sitemap.xml` 文件生成 `llms.txt`。
- Firecrawl 也提供了一个名为 `llmstxt` 的工具，它使用 Firecrawl 的爬虫来生成 `llms.txt` 文件。Firecrawl 还提供了一个功能齐全的 AI 爬虫，可以创建 `llms.txt` 文件，并为大型平台提供在线生成器。
- Mintlify 是一个文档平台，内置了 `llms.txt` 的生成功能，可以为托管的文档自动生成 `/llms.txt` 和 `/llms-full.txt`。
- Microsoft 的 MarkItDown、Jina AI 的 Reader API 等，可以把任意内容转换为 Markdown，适合用来从没有直接纯文字驱动的网站生成 llms-full.txt。
- 也有一些 WordPress 插件可以用来创建和管理 `/llms.txt` 文件。

下表列出了一些可用于生成 `llms.txt` 文件的工具：

| **工具名称**            | **描述**                | **生成方法**                | **参考链接**                                       |
| ----------------------- | ----------------------- | --------------------------- | ------------------------------------------------------------ |
| `llmstxt` by dotenv     | 开源命令行工具          | 基于 `sitemap.xml` 文件生成 | https://github.com/dotenvx/llmstxt                      |
| `llmstxt` by Firecrawl  | 使用 Firecrawl 爬虫生成 | 抓取网站内容                | https://llmstxt.firecrawl.dev/                               |
| Mintlify                | 文档平台                | 自动生成                    | https://mintlify.com/                                        |
| MarkItDown by Microsoft | 内容转换为 Markdown      | 手动转换内容              | https://github.com/microsoft/markitdown                         |
| SLM (Reader API) by Jina AI | 内容转换为 Markdown | 手动转换内容        | https://jina.ai/reader/                        |
| LLMs.txt Generator                | WordPress 插件          | 自动创建和管理              | https://wordpress.org/plugins/llms-txt-generator/ |

当然，这个领域还有很多空白。因此，为你喜欢的网站内容生成工具添加 llms-txt 的支持，也许是一个你向这个项目开始进行贡献的很好的途径。

许多网站已经开始实施 `llms.txt` 标准，并展示了其在不同场景下的实际应用。我们可以在 [llms.txt hub](https://llmstxthub.com) 上找到很多现成的示例，比如：

- [Cloudflare](https://llmstxthub.com/website/cloudflare)
- [Anthropic](https://docs.anthropic.com/llms.txt)
- [Perplexity](https://llmstxthub.com/website/perplexity)
- [ElevenLabs](https://llmstxthub.com/website/elevenlabs)
- [Cursor](https://llmstxthub.com/websites/cursor)

这个标准非常适合用来帮助 LLM 在上下文中索引文档，如果你的网站也实现了 llms.txt，不妨尝试将它们也提交到 llms.txt hub，让大家更容易发现它！

### 维护有效的 llms.txt

为了确保 `llms.txt` 文件的有效性，定期更新至关重要。当网站结构发生变化时，应及时更新 `llms.txt` 文件，以确保 AI 系统获得最新的信息。我们应该使用自动化的工具来生成和更新 `llms.txt`。过时的 `llms.txt` 文件可能会误导 LLMs，反而抵消其带来的益处。

在 `/llms.txt` 文件中，应有选择地包含最重要的资源，并将不太重要的内容放在可选部分。`/llms.txt` 的目标是提供精简的概述，因此只包含最关键的资源可以使其保持简洁有效。

对于 `/llms-full.txt` 文件，建议对其进行优化以提高 AI 的处理效率：移除不必要的标记和脚本，使 AI 模型能够专注于重要的核心内容。

## 总结：面向 AI 的网络内容

采用 `llms.txt` 标准为 LLMs 和网站所有者都带来了显著的优势。对于 LLMs 而言，它提供了结构化的、易于理解的内容概述，提高了信息检索的效率和准确性。对于网站所有者而言，它可以提高在 AI 平台上的可见性，优化资源利用，并可能带来潜在的 SEO 优势和用户信任度的提升。

`llms.txt` 代表着一种向 AI 优先的文档策略的转变。正如面向搜索引擎的 SEO 曾经至关重要一样，拥有 AI 可读的内容在很近的未来也会变得举足轻重。随着越来越多的网站采用该文件，相信新的工具和最佳实践将会涌现。`llms.txt` 为帮助 AI 系统更好地理解和利用网络内容（特别是技术文档和 API）提供了一个切实可行的解决方案。各行各业对 `llms.txt` 的采用正在加速。通过提供对机器友好数据的确定性访问，`llms.txt` 降低了延迟，提高了准确性，并使组织能够站在 LLM 优化网络的前沿。

可以预见，随着 AI 与网络的融合不断加深，和 [MCP 一样](https://onevcat.com/2025/02/mcp/)，`llms.txt` 也会成为一个越来越重要的标准。
